{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dea9f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for AI module: fdd_utils/ai_helper.py\n",
    "from fdd_utils.ai_helper import AIHelper\n",
    " \n",
    "# Define system prompt and user prompt\n",
    "system_prompt = r\"\"\"You are a helpful assistant.\"\"\"\n",
    "user_prompt = r\"\"\"Whehre is HK?\"\"\"\n",
    " \n",
    "# Choose the model type ('openai', 'local', 'deepseek')\n",
    "model_type = \"local\"\n",
    " \n",
    "# Create an instance of the AIHelper\n",
    "ai_helper = AIHelper(model_type=model_type, user_prompt=user_prompt, system_prompt=system_prompt)\n",
    " \n",
    "# Get the response from the AI model\n",
    "response = ai_helper.get_response()\n",
    "print(response)\n",
    " \n",
    "# AI module test pass\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13241ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databook handling\n",
    "from fdd_utils.process_databook import extract_data_from_excel\n",
    "import warnings\n",
    " \n",
    "# Ignore the user warning for data validation\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    " \n",
    "# Usage:\n",
    "# Eng (Haining 3 entites): 221128.Project TK.Databook.JW.xlsx\n",
    "# Semi Databook: deli.xlsx\n",
    "databook_path = \"inputs/221128.Project TK.Databook.JW.xlsx\"\n",
    "# Chi (single entity): 240624.è”æ´‹-databook.xlsx || 240627.ä¸œèŽžå²­å—-databook.xlsx\n",
    "# databook_path = \"inputs/240627.ä¸œèŽžå²­å—-databook.xlsx\"\n",
    "entity_name = 'Haining Wanpu' # Lianyang, Dongguan Lingnan\n",
    "mode = \"BS\" # BS, IS, All\n",
    " \n",
    "dfs, workbook_list, result_type, report_language = extract_data_from_excel(databook_path, entity_name, mode)\n",
    " \n",
    "# workbook_list\n",
    "print('Key list:', workbook_list)\n",
    " \n",
    "# Example databook data for single item\n",
    "# dfs['Cash']\n",
    " \n",
    "# Excel processing module ok, individual steps inside workings/process_databook.ipynb\n",
    "# Results -> Pass\n",
    "# Remark: here key list = workbook tabname\n",
    "# è”æ´‹, ä¸œèŽžå²­å— IS, BS - pass\n",
    " \n",
    "# one issue: å¯èƒ½æœƒæœ‰subtotal+ç´°é …çš„è¡¨é”æ–¹æ³•, ä¹‹å¾Œè¦å°å¿ƒï¼Œå¦‚æžœAIæœ‰bugè¦è¿”å‘¢åº¦æ”¹\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf9c1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['Cash']\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_language\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7f4242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key reconciliation\n",
    " \n",
    "# mapping.json\n",
    "# \"Cash\", \"AR\", \"Prepayments\", \"OR\", \"Inventory\", \"IP\", \"IA\", \"NCA\", \"NCL\", \"Other NCA\", \"Other CA\", \"AP\", \"Advances\",\n",
    "# \"Tax payable\", \"OP\", \"Capital\", \"Reserve\", \"Capital reserve\", \"R/E\", \"OI\", \"OC\", \"Tax and Surcharges\", \"GA\",\n",
    "# \"Fin Exp\",  \"Cr Loss\", \"Other Income\", \"Non-operating Income\", \"Non-operating Exp\", \"Income tax\", \"LT DTA\", \"Selling cost\"\n",
    " \n",
    "# pattern.json\n",
    "# \"Cash\", \"AR\", \"Prepayments\", \"OR\", \"IP\", \"NCA\", \"Other NCA\", \"Other CA\", \"AP\", ## å°‘å·¦: \"Inventory\"ï¼Œ \"IA\"ï¼Œ \"NCL\", \"Advances\"\n",
    "# \"Tax payable\", \"OP\", \"Capital\", \"Reserve\", \"OI\", \"OC\", \"Tax and Surcharges\", \"GA\", ## å°‘å·¦: \"Capital reserve\", \"R/E\"\n",
    "# \"Fin Exp\", \"Cr Loss\", \"Other Income\", \"Non-operating Income\", \"Non-operating Exp\", \"Income tax\", \"LT DTA\" ## å°‘å·¦: \"Capital reserve\", \"R/E\", \"Selling cost\"\n",
    " \n",
    "# prompts.json\n",
    "# \"Cash\", \"AR\", \"Other NCA\", \"Other CA\", \"AP\" ## å°‘å·¦: \"Prepayments\", \"OR\", \"Inventory\", \"IP\", \"IA\", \"NCA\", \"NCL\", \"Advances\"\n",
    "# \"Reserve\", \"Capital reserve\", \"R/E\", \"OI\", \"OC\", \"Tax and Surcharges\", \"GA\", ## å°‘å·¦: \"Tax payable\", \"OP\", \"Capital\",\n",
    "# \"Fin Exp\",  \"Cr Loss\", \"Other Income\", \"Non-operating Income\", \"Non-operating Exp\", \"Income tax\", \"LT DTA\", ## å°‘å·¦: \"Selling cost\"\n",
    " \n",
    "# åˆ°æ™‚è¦åŠ è¿”ä¸ŠåŽ» ä»¥mappingsçˆ²æº–\n",
    "# Keys checked identical    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693fd148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Agent ç”±å‘¢åº¦é–‹å§‹è¦+language\n",
    " \n",
    "# Agent 1: æ ¹æ“šacctæƒ…æ³æ€pattern+draft Input=language, key(account, pattern) Output=key+AI output\n",
    "# Agent 2ï¼šå°æ•¸å­—(+desc)ä¿‚å’ªå²© Input=AI output + key(accounts)\n",
    "# Agent 3: compliance -> æª¢æŸ¥å†…å®¹ä¿‚å’ªmake sense\n",
    "# Agent 4: translate\n",
    " \n",
    "# ç›¡é‡+heuristic features å°¤å…¶on å®¹æ˜“ç‡åˆ°å•é¡Œå˜…ä½ç½®\n",
    " \n",
    "# Expand options: 1. industry 2.RAG\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fd1162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fdd_utils.content_generation import content_generate\n",
    " \n",
    "agent = 'agent_1'\n",
    "model_name = 'local'\n",
    "report_language = 'Eng' # Eng, Chi\n",
    " \n",
    "content_generate(agent, workbook_list, model_name, report_language, dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0259df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Run Agent 2 to verify and refine the output of Agent 1\n",
    "for mapping_key in mapping_keys:\n",
    "    result = load_and_verify(agent2, mapping_key)  # Implement a function to load and check results\n",
    " \n",
    "    if result:\n",
    "        # Implement AI processing for verification and refinement\n",
    "        system_prompt = f\"System prompt for {agent2} verification.\"\n",
    "        user_prompt = f\"User prompt containing data verification specifics for {mapping_key}.\"\n",
    "           \n",
    "        ai_helper = AIHelper(model_type=model_name, user_prompt=user_prompt, system_prompt=system_prompt)\n",
    "        verification_response = ai_helper.get_response().strip()\n",
    " \n",
    "        # Final verification step: ensure format compliance and log or output appropriately\n",
    "        verification_response = verification_response.replace(\"\\n\\n\", \"\\n\").replace(\"\\n \\n\", \"\\n\")\n",
    "        print(f\"Verified Output for key {mapping_key}: {verification_response}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfac1ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, yaml\n",
    " \n",
    "def read_result_by_key(mapping_key, log_dir='fdd_utils'):\n",
    "    intermediate_file = os.path.join(log_dir, 'intermediate_results.yml')\n",
    "    if not os.path.exists(intermediate_file):\n",
    "        print(\"Intermediate file does not exist.\")\n",
    "        return None\n",
    " \n",
    "    with open(intermediate_file, 'r', encoding='utf-8') as file:\n",
    "        data = yaml.safe_load(file) or {}\n",
    " \n",
    "    result_data = data.get(mapping_key, None)\n",
    "    return result_data.get('result') if result_data else None\n",
    " \n",
    "# Example usage to read the result by key\n",
    "result = read_result_by_key('AR')\n",
    "print(result)\n",
    " \n",
    "# ['Cash', 'AR', 'Prepayments', 'OR', 'Other current assets', 'Investment properties', 'Tax payable', 'OP', 'AP', 'Share capital']\n",
    "# AR - Haining issue\n",
    "# General: 1 d.p., 1000Kshould = M 3. all amount should be CNYxxxK or million\n",
    " \n",
    "# Agent 1 completed with some issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d28dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Test may start here #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0970e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Test New AIHelper with Agent Support\n",
    "# Test for enhanced AI module: fdd_utils/ai_helper.py\n",
    "from fdd_utils.ai_helper import AIHelper\n",
    "\n",
    "# Test 1: Basic AIHelper with agent\n",
    "print(\"=\"*60)\n",
    "print(\"TEST 1: Basic AIHelper with Agent Support\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create an instance with agent_1\n",
    "ai_helper = AIHelper(\n",
    "    model_type='local',  # or 'deepseek', 'openai'\n",
    "    agent_name='agent_1',\n",
    "    language='Eng',\n",
    "    use_heuristic=False\n",
    ")\n",
    "\n",
    "# Simple test prompt\n",
    "user_prompt = \"Where is Hong Kong?\"\n",
    "system_prompt = \"You are a helpful assistant.\"\n",
    "\n",
    "# Get response\n",
    "response = ai_helper.get_response(user_prompt, system_prompt)\n",
    "\n",
    "print(\"\\nResponse content:\", response['content'])\n",
    "print(f\"Mode: {response['mode']}\")\n",
    "print(f\"Duration: {response['duration']:.2f}s\")\n",
    "print(f\"Tokens: {response['tokens_used']}\")\n",
    "print(\"\\nâœ… AIHelper test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822455b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Test Databook Extraction (Should Still Work)\n",
    "# Test databook handling with language detection\n",
    "from fdd_utils.process_databook import extract_data_from_excel\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TEST 2: Databook Extraction\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Your existing paths\n",
    "databook_path = \"inputs/221128.Project TK.Databook.JW.xlsx\"\n",
    "entity_name = 'Haining Wanpu'\n",
    "mode = \"BS\"  # BS, IS, All\n",
    "\n",
    "# Extract data (same as before, but now with better language detection)\n",
    "dfs, workbook_list, result_type, report_language = extract_data_from_excel(\n",
    "    databook_path, entity_name, mode\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Extracted {len(workbook_list)} worksheets\")\n",
    "print(f\"Result type: {result_type}\")\n",
    "print(f\"Detected language: {report_language}\")\n",
    "print(f\"Keys: {workbook_list[:5]}...\")  # Show first 5\n",
    "\n",
    "# Check a sample\n",
    "if 'Cash' in dfs:\n",
    "    print(f\"\\nSample data (Cash):\")\n",
    "    print(dfs['Cash'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b211afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Test New AI Pipeline - Quick Method\n",
    "# Test the new AI pipeline - Quick method\n",
    "from fdd_utils.ai_pipeline import run_quick_pipeline\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TEST 3: Quick Pipeline Execution\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Quick test with heuristic mode (no API calls, fast)\n",
    "print(\"\\nRunning with HEURISTIC mode (no AI calls)...\")\n",
    "results = run_quick_pipeline(\n",
    "    databook_path=databook_path,\n",
    "    entity_name=entity_name,\n",
    "    mode='BS',\n",
    "    model_type='local',\n",
    "    language=report_language or 'Eng'\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Quick pipeline completed!\")\n",
    "print(f\"Processed {len(results)} items\")\n",
    "\n",
    "# Show first result\n",
    "first_key = list(results.keys())[0] if results else None\n",
    "if first_key:\n",
    "    print(f\"\\nSample result for '{first_key}':\")\n",
    "    print(results[first_key][:200] + \"...\" if len(results[first_key]) > 200 else results[first_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd00fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Test Full Pipeline with Orchestrator\n",
    "# Test with the orchestrator (recommended method)\n",
    "from fdd_utils.ai_pipeline import AIPipelineOrchestrator\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TEST 4: Full AI Pipeline with Orchestrator\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize orchestrator\n",
    "orchestrator = AIPipelineOrchestrator(config_path='fdd_utils/config.yml')\n",
    "\n",
    "# Load data (reusing the variables from Cell 2)\n",
    "print(\"\\nLoading data...\")\n",
    "data_info = orchestrator.load_data(\n",
    "    databook_path=databook_path,\n",
    "    entity_name=entity_name,\n",
    "    mode='BS'\n",
    ")\n",
    "\n",
    "print(f\"âœ… Loaded {len(data_info['mapping_keys'])} worksheets\")\n",
    "print(f\"Detected language: {data_info['report_language']}\")\n",
    "\n",
    "# Run full pipeline with HEURISTIC mode first (for testing, no API costs)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Running FULL PIPELINE (Heuristic Mode - Testing)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = orchestrator.run_full_pipeline(\n",
    "    model_type='local',\n",
    "    language=data_info['report_language'],\n",
    "    use_heuristic=True,  # Set to False to use real AI\n",
    "    use_multithreading=True,\n",
    "    max_workers=4\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "orchestrator.print_results_summary()\n",
    "\n",
    "# Save results\n",
    "orchestrator.save_results('fdd_utils/output/test_results.yml')\n",
    "print(\"\\nâœ… Full pipeline test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925411d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Test Individual Agents\n",
    "# Test running individual agents\n",
    "print(\"=\"*60)\n",
    "print(\"TEST 5: Individual Agents\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Reinitialize orchestrator with fresh data\n",
    "orchestrator = AIPipelineOrchestrator()\n",
    "orchestrator.load_data(databook_path, entity_name, 'BS')\n",
    "\n",
    "# Run only Agent 1 (Content Generator)\n",
    "print(\"\\n--- Running Agent 1 Only ---\")\n",
    "results_agent_1 = orchestrator.run_agent_only(\n",
    "    agent_name='agent_1',\n",
    "    model_type='local',\n",
    "    language='Eng',\n",
    "    use_heuristic=True  # Set to False for real AI\n",
    ")\n",
    "\n",
    "print(f\"âœ… Agent 1 completed: {len(results_agent_1)} items\")\n",
    "\n",
    "# Show a sample result\n",
    "sample_key = list(results_agent_1.keys())[0]\n",
    "print(f\"\\nAgent 1 output for '{sample_key}':\")\n",
    "print(results_agent_1[sample_key][:300] + \"...\")\n",
    "\n",
    "# Run Agent 2 with Agent 1's results\n",
    "print(\"\\n--- Running Agent 2 Only (with Agent 1 results) ---\")\n",
    "results_agent_2 = orchestrator.run_agent_only(\n",
    "    agent_name='agent_2',\n",
    "    previous_results=results_agent_1,\n",
    "    model_type='local',\n",
    "    language='Eng',\n",
    "    use_heuristic=True\n",
    ")\n",
    "\n",
    "print(f\"âœ… Agent 2 completed: {len(results_agent_2)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32378947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Test Sequential Agents\n",
    "# Test running specific agents in sequence\n",
    "print(\"=\"*60)\n",
    "print(\"TEST 6: Sequential Agents (Custom Order)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "orchestrator = AIPipelineOrchestrator()\n",
    "orchestrator.load_data(databook_path, entity_name, 'BS')\n",
    "\n",
    "# Run only agents 1, 2, and 4 (skip agent 3 if desired)\n",
    "results = orchestrator.run_sequential_agents(\n",
    "    agents=['agent_1', 'agent_2', 'agent_4'],  # Custom agent sequence\n",
    "    model_type='local',\n",
    "    language='Eng',\n",
    "    use_heuristic=True  # Set to False for real AI\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Sequential agents completed: {len(results)} items\")\n",
    "\n",
    "# Compare with full pipeline\n",
    "orchestrator.print_results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3247f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Test with REAL AI (DeepSeek)\n",
    "# Test with real AI (replace heuristic with actual AI)\n",
    "print(\"=\"*60)\n",
    "print(\"TEST 7: Real AI Pipeline (DeepSeek)\")\n",
    "print(\"=\"*60)\n",
    "print(\"âš ï¸  This will use API credits!\")\n",
    "\n",
    "# Make sure your API key is configured in config.yml first!\n",
    "confirm = input(\"Run with real AI? This will use API credits. (yes/no): \")\n",
    "\n",
    "if confirm.lower() == 'yes':\n",
    "    orchestrator = AIPipelineOrchestrator()\n",
    "    orchestrator.load_data(databook_path, entity_name, 'BS')\n",
    "    \n",
    "    # Run with REAL AI\n",
    "    results = orchestrator.run_full_pipeline(\n",
    "        model_type='local',  # or 'deepseek' if configured\n",
    "        language=report_language or 'Eng',\n",
    "        use_heuristic=False,  # Real AI!\n",
    "        use_multithreading=True,\n",
    "        max_workers=4\n",
    "    )\n",
    "    \n",
    "    # Save results\n",
    "    orchestrator.save_results('fdd_utils/output/real_ai_results.yml')\n",
    "    orchestrator.print_results_summary()\n",
    "    \n",
    "    # Show a detailed result\n",
    "    sample_key = 'Cash' if 'Cash' in results else list(results.keys())[0]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Detailed result for '{sample_key}':\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(results[sample_key])\n",
    "    \n",
    "    print(\"\\nâœ… Real AI pipeline completed!\")\n",
    "else:\n",
    "    print(\"Skipped real AI test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795462dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: View Results and Logs\n",
    "# View results and check logs\n",
    "import yaml\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TEST 8: View Results and Logs\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check intermediate results (if exists from old system)\n",
    "intermediate_file = 'fdd_utils/intermediate_results.yml'\n",
    "if os.path.exists(intermediate_file):\n",
    "    with open(intermediate_file, 'r', encoding='utf-8') as f:\n",
    "        old_results = yaml.safe_load(f)\n",
    "    print(f\"\\nðŸ“ Old intermediate results: {len(old_results)} items\")\n",
    "\n",
    "# Check new log files\n",
    "log_dir = 'fdd_utils/logs'\n",
    "if os.path.exists(log_dir):\n",
    "    log_files = sorted(glob(os.path.join(log_dir, 'ai_processing_*.log')))\n",
    "    data_files = sorted(glob(os.path.join(log_dir, 'ai_data_*.yml')))\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ Log files: {len(log_files)}\")\n",
    "    print(f\"ðŸ“Š Data files: {len(data_files)}\")\n",
    "    \n",
    "    # Show latest log file name\n",
    "    if log_files:\n",
    "        latest_log = log_files[-1]\n",
    "        print(f\"\\nLatest log: {os.path.basename(latest_log)}\")\n",
    "        \n",
    "        # Read last 20 lines\n",
    "        with open(latest_log, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            print(\"\\nLast 20 lines of log:\")\n",
    "            print(\"\".join(lines[-20:]))\n",
    "    \n",
    "    # Show latest data file summary\n",
    "    if data_files:\n",
    "        latest_data = data_files[-1]\n",
    "        print(f\"\\nðŸ“Š Latest data file: {os.path.basename(latest_data)}\")\n",
    "        \n",
    "        with open(latest_data, 'r', encoding='utf-8') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "            \n",
    "        if 'summary' in data:\n",
    "            print(\"\\nSummary:\")\n",
    "            for key, value in data['summary'].items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "\n",
    "# Check saved results\n",
    "output_file = 'fdd_utils/output/test_results.yml'\n",
    "if os.path.exists(output_file):\n",
    "    with open(output_file, 'r', encoding='utf-8') as f:\n",
    "        results = yaml.safe_load(f)\n",
    "    print(f\"\\nâœ… Saved results file exists: {len(results)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d579d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Performance Comparison\n",
    "# Compare performance: single-threaded vs multi-threaded\n",
    "import time\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TEST 9: Performance Comparison\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test with smaller dataset or heuristic mode for speed\n",
    "orchestrator = AIPipelineOrchestrator()\n",
    "orchestrator.load_data(databook_path, entity_name, 'BS')\n",
    "\n",
    "# Take only first 5 items for testing\n",
    "test_keys = workbook_list[:5]\n",
    "test_dfs = {k: dfs[k] for k in test_keys if k in dfs}\n",
    "\n",
    "print(f\"\\nTesting with {len(test_keys)} items\")\n",
    "\n",
    "# Test 1: Without multi-threading\n",
    "print(\"\\n--- Test 1: Single-threaded ---\")\n",
    "from fdd_utils.content_generation import ai_pipeline_full\n",
    "\n",
    "start = time.time()\n",
    "results_single = ai_pipeline_full(\n",
    "    mapping_keys=test_keys,\n",
    "    dfs=test_dfs,\n",
    "    model_type='local',\n",
    "    language='Eng',\n",
    "    use_heuristic=True,\n",
    "    use_multithreading=False\n",
    ")\n",
    "time_single = time.time() - start\n",
    "\n",
    "print(f\"Time: {time_single:.2f}s\")\n",
    "\n",
    "# Test 2: With multi-threading\n",
    "print(\"\\n--- Test 2: Multi-threaded (4 workers) ---\")\n",
    "start = time.time()\n",
    "results_multi = ai_pipeline_full(\n",
    "    mapping_keys=test_keys,\n",
    "    dfs=test_dfs,\n",
    "    model_type='local',\n",
    "    language='Eng',\n",
    "    use_heuristic=True,\n",
    "    use_multithreading=True,\n",
    "    max_workers=4\n",
    ")\n",
    "time_multi = time.time() - start\n",
    "\n",
    "print(f\"Time: {time_multi:.2f}s\")\n",
    "\n",
    "# Compare\n",
    "if time_multi > 0:\n",
    "    speedup = time_single / time_multi\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"âš¡ Speedup: {speedup:.2f}x faster with multi-threading\")\n",
    "    print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
